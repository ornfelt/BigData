{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ab10e3-cfdc-443f-a702-7a42697bec5a",
   "metadata": {},
   "source": [
    "#  TESTA BERT\n",
    "\n",
    "Attribution: Chris McCormick and Nick Ryan. (2019, May 14). BERT Word Embeddings Tutorial. Retrieved from http://www.mccormickml.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec7bb-9914-482a-bb85-d05d03d354c1",
   "metadata": {},
   "source": [
    "## 1. Hämta en BERT modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb40c9a-7780-4ba6-92da-ebe41f70b6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7d236923b64eab9e2f4820cb46a3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec81d6e82ad47efb7173aae740e2a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4c51c5746c4f0ab63f525e1c4eb2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ladda en förtränad BERT-modell\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e198fd-30f6-4b1c-85ee-fb523129e351",
   "metadata": {},
   "source": [
    "## Formatera input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7e2512-4f26-470d-bf20-996115baf827",
   "metadata": {},
   "source": [
    "### Testa BERTS tokenizerare för att formatera input till korrekt format för BERT\n",
    "\n",
    "BERT kan ta en eller två meningar som input\n",
    "\n",
    "Först kommer alltid [CLS] och mellan varje mening kommer [SEP]\n",
    "\n",
    "Att annotera meningar med [SEP] kan göras automatiskt. Alla meningar måste ha samma längd, även detta kan ordnas automatiskt, men man kan behöva kontrollera att det blivit som man tänkt sig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f168c13-0f94-4481-911f-868cf889d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Skriv en mening här, vad som helst.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624800d7-52b8-45db-84af-aabcdbf9ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista lite ord som finns i base BERT:s vokabulär\n",
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ae01d5-1349-4fbd-a673-8e18b37f4765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Skriv en ny mening där du inkluderar ett ord som har olika betydelse\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Lägg till de viktiga specialtokens som BERT kräver.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Dela upp meningarna i tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Mappa tokens till index i vokabuläret \n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Visa orden med deras index \n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186f65b-467d-4f3e-becd-2dfc0881cd0d",
   "metadata": {},
   "source": [
    "### Segment ID\n",
    "\n",
    "BERT förväntar sig parvisa meningar där det är tydligt vilka ord som för till vilken mening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f264cb-e705-493b-a046-783919e08e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Vi har bara en mening, alltså tillhör alla våra tokens mening 1\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50ec1d-171b-41d2-8f6d-cc2c982b0c6b",
   "metadata": {},
   "source": [
    "## Extrahera embeddings\n",
    "\n",
    "Vi använder oss här av Torch bilioteket vilken förväntar sig tensors, inte listor eller tuples. Därför måste vi skapa tensorer, det förändrar inte själva data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8382b5-6ba2-4a5f-9b2f-3b6784ff347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertera input till PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13523b1f-e049-42a4-a16a-1cae043fec1d",
   "metadata": {},
   "source": [
    "### Kör BERT med vår mening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02c916c-f480-4919-8974-3d1cc6bc35cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58784a78cec4319972ec7cea88b0ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ladda den förtränade modellen (vikterna för modellen)  \n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Om modellen ska returnera alla hidden states dvs alla vektorer som skapats\n",
    "                                  )\n",
    "\n",
    "# Feed forward mode, kallas för evaluation mode. Det finns flera andra för att utföra andra uppgifter \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cbfa255-0b20-4691-80c9-638854fd0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kör din text genom BERT. och samla alla hidden states som producerats från alla 12 lager i BERT. no_grad nedan innebär att vi inte räknar ut hur det gick, \n",
    "# eftersom vi inte ska bakåtpropagera, eftersom vi inte tränar, sparar minne.  \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # När vi utvärderar modellen kommer den returnera ett antal objekt, beroende på hur den är konfigurerad. Eftersom vi satt output_hidden_state = True\n",
    "    # Så kommer det tredje objektet att vara hidden state från alla lager. Se dokumentationen för detlajer: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfbe0d5-15a0-4f88-b054-d6195125403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0f04e-7544-4f29-8cd2-3814d9bd2735",
   "metadata": {},
   "source": [
    "Alla hidden states för modellen är nu lagrade i objektet hidden_states. Objektet har däremd 4 dimensioner.  \n",
    "\n",
    "* The layer number (13 layers)\n",
    "* The batch number (1 sentence)\n",
    "* The word / token number (Hur många tokens i din mening?)\n",
    "* The hidden unit / feature number (768 features)\n",
    "\n",
    "Varför 13 lager? BERT base har ju 12? Det första elementet är input embeddingen, resten är output från varje lager av de 12 lager som BERT har. \n",
    "Det innebär att vår mening har ?? unika värden bara för en enda mening! \n",
    "\n",
    "Den andra dimensionen, batch size, används när man ska ge modellen flera meningar samtidigt. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d85391-3433-4464-a70b-37fcce5b0b33",
   "metadata": {},
   "source": [
    "# So what?¨\n",
    "\n",
    "För varje token vi matat in i BERT har den spottat ur sig 13 separata vectorer, varje har en längd på 768 \n",
    "\n",
    "Vi har alltså en mängd gigantiska vektorer som representerar vår enda mening vi matat in. Vad ska vi göra nu? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646ad3b-387f-43c1-a36e-5424231453a0",
   "metadata": {},
   "source": [
    "## Skapa vektorer för ord och meningar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f1dcc7-c9c0-4edc-8c2d-7b7a2b67d9d3",
   "metadata": {},
   "source": [
    "Från alla dessa vektorer så kan vi skapa vektorer för varje enskilt ord eller för en hel mening genom att kombinera vektorer från olika lager. Vi vet dock inte exakt vilka kombinationer som är \"bäst\" för att representera vår mening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f9f4b55-2737-49a7-87e3-6e11648521f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 22, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Konkatenera tensorerna för alla lager och skapa en ny dimension i tensorn. \n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e288e6-019b-4be7-9900-8f7f662bbb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 22, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ta bort dimentionen som representerar batches eftersom vi bara har en mening.\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587a946e-7b54-47be-a91d-60c156e586ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 13, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Byt plats på dimension 0 och 1 för att få tokens först i tensorn (grupperad på tokens)\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b03bc-5611-4076-8edc-2504661348e7",
   "metadata": {},
   "source": [
    "### Ordvektorer\n",
    "\n",
    "Finns som sagt flera sätt att skapa vektorer, ett sätt att att konkatenera de sista fyra lagren. Ett annat att summera de sista fyra lagren. Båda är kodade nedan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4da9a87a-b214-44a2-be81-9ec97b436534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storleken är: 22 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Spara token vektorer, med storlek [22 * 3 072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `Embeddings för tokens är en tensor med dimensionerna [22 x 12 x 768] \n",
    "\n",
    "# För varje token i vår mening...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` är en [12 x 768] tensor\n",
    "\n",
    "    # Conkatenera vektorerna\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Använd `cat_vec` för att representera `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Storleken är: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b4e4d6-f909-49fd-b281-cce3909396e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storleken är: 22 x 768\n"
     ]
    }
   ],
   "source": [
    "# Spara tokenvectorer med storlek [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` är en [22 x 12 x 768] tensor.\n",
    "\n",
    "\n",
    "for token in token_embeddings:\n",
    "    #Summera de fyra sista lagren\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Storleken är: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fe31d-a1df-4bc8-91d5-57c7b8483ca8",
   "metadata": {},
   "source": [
    "### Vektor för meningar\n",
    "\n",
    "Återigen finns flera olika sätt, vilket som är bäst beror på vad man vill göra. Enkelt sätt är att ta medelvärdet för alla lager från lager 2 till sista lagret. Då blir resultatet en vektor med längd 768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e54fbe35-6b37-487a-bc86-091f717179b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# `hidden_states` har storleken [13 x 1 x 22 x 768]\n",
    "\n",
    "# `token_vecs` är en tensor med storleken [22 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Beräkna medelvärdet för alla 22 tokens\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50a62c-22d6-405e-9812-0a7bba11fc57",
   "metadata": {},
   "source": [
    "### Har samma ord betydelse som beror på kontexten (orden omkring)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9209c580-8af2-4044-8ea6-348c1bbee9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 after\n",
      "2 stealing\n",
      "3 money\n",
      "4 from\n",
      "5 the\n",
      "6 bank\n",
      "7 vault\n",
      "8 ,\n",
      "9 the\n",
      "10 bank\n",
      "11 robber\n",
      "12 was\n",
      "13 seen\n",
      "14 fishing\n",
      "15 on\n",
      "16 the\n",
      "17 mississippi\n",
      "18 river\n",
      "19 bank\n",
      "20 .\n",
      "21 [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Vilka index finns vårt ord med flera betydelser på? \n",
    "for i, token_str in enumerate(tokenized_text):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74048a2e-f520-45fe-81de-1d55ad783c06",
   "metadata": {},
   "source": [
    "Index 6, 10, och 19.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b29e24c-d196-4542-8d3c-1f1f3902bfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Första 5 vektorvärdena för varje instans av ordet\n",
      "\n",
      "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
      "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
      "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
     ]
    }
   ],
   "source": [
    "print('Första 5 vektorvärdena för varje instans av ordet')\n",
    "print('')\n",
    "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881d3ac-4400-4ce3-b2f1-b5e15d22080a",
   "metadata": {},
   "source": [
    "Vi kan se att de är olika, men för säkerhetsskull kan vi beräkna cosinuslikheten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a189a56-4cf4-4cb6-97da-c001c0f5225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likhet för *liknande*  betydelse:  0.94\n",
      "Likhet för *olik* betydelse:  0.69\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Beräkna cosinuslikehten mellan ordets olika betydelse \n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "\n",
    "# Beräkna för ordet i lika betydelse\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Likhet för *liknande*  betydelse:  %.2f' % same_bank)\n",
    "print('Likhet för *olik* betydelse:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7719589-9579-45c2-8777-63a381167ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
