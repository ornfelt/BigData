{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia av Laboration_2_part_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p_jDRfC0gAQA",
        "B09PSRsLnaXV",
        "Mil-c46_A5Vu",
        "5eBx1abqgiBf",
        "XVjHs1rrA5Vx",
        "vBvL0bZ4A5Vy",
        "juL23IJ8A5V2",
        "ERtrQNohA5V2",
        "x_8j8Sb5A5V5",
        "SF5Zpx1wA5V5"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2IS239-Data-Analytics/laboration2-grupp-5/blob/master/Kopia_av_Laboration_2_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVkuY_jwxiaS"
      },
      "source": [
        "# Laboration 2 part 1: \n",
        "\n",
        "In this first part of laboration 2 you will practice some aspects of data wrangling and descriptive statistics on a structured dataset. \n",
        "\n",
        "Make sure to read all instructions carefully and also to answer all questions. Questions are marked with **Q** in the laboration. Always answer these questions directly after it is posed, using markdown language. \n",
        "\n",
        "There are also a number of coding exercises without specific questions attached. These also have to be coded in order to pass the laboration. \n",
        "\n",
        "The dataset used in this laboration is called *modcloth_final_data.json* and is located in the data folder in the repository for laboration 2. \n",
        "\n",
        "To hand in the laborations only provide the link to the finished Colaboratory notebook in Studium, or hand in a HTML-file with all the cells executed to show the output. \n",
        "\n",
        "Good luck!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWj4kKqLA5Vk"
      },
      "source": [
        " Copyright 2018 Aditya Agrawal\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "The content in this notebook has been subjected to changes in order to make it fit with the course Data Analytics 2IS239 at Uppsala University Campus Gotland.\n",
        "\n",
        "\n",
        "### About the dataset\n",
        "\n",
        ">This dataset contains self-reported clothing-fit feedback from customers as well as other side information like reviews, ratings, product categories, catalog sizes, customers’ measurements (etc.) from [Modcloth](http://modcloth.com)\n",
        "\n",
        ">ModCloth sells women’s vintage clothing and accessories, from which the curator of the dataset collected data from three categories: dresses, tops, and bottoms. RentTheRunWay is a unique platform that allows women to rent clothes for various occasions; they collected data from several categories. \n",
        ">\n",
        ">**Note:** In the dataset, fit feedback belongs to one of three classes: ‘Small,’ ‘Fit,’ and ‘Large.’ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rNQm12gCJko"
      },
      "source": [
        "Start you work by importing the following libraries that you will use during this part of the lab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO1YUkF7A5Vq"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Suppressing all warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rc('figure', figsize = (20, 8))\n",
        "matplotlib.rc('font', size = 14)\n",
        "matplotlib.rc('axes.spines', top = False, right = False)\n",
        "matplotlib.rc('axes', grid = False)\n",
        "matplotlib.rc('axes', facecolor = 'white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1KDzywGA5Vr"
      },
      "source": [
        "#  [Modcloth](http://modcloth.com) Dataset\n",
        "\n",
        "## Importing data using Pandas\n",
        "\n",
        "The following lines of code imports the json dataset into a pandas dataframe, given that the file is stored in your gdrive. This requires you to clone your repo into gDrive. If you want to, you can also get it directly from your repository at GitHub or upload it from your local computer (if you have cloned your repository on your local computer).\n",
        "\n",
        "If you are interested in creating your own solutions that perhaps are nicer than this, please see for instance: \n",
        "\n",
        "[Connecting github to Colaboratory](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-u2zzbJFb-F"
      },
      "source": [
        "#Mounting gDrive in Colaboratory\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive/\", force_remount=True)\n",
        "    google_drive_prefix = \"/content/drive/My Drive\"\n",
        "    data_prefix = \"{}/mnist/\".format(google_drive_prefix)\n",
        "except ModuleNotFoundError: \n",
        "    data_prefix = \"data/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiGd20cqktyj"
      },
      "source": [
        "To change directory to the folder where the files you want to work with are located you have to use magic commands. See for instance [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html), or [here](https://www.tutorialspoint.com/jupyter/ipython_magic_commands.htm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buXbDdWrBeHG"
      },
      "source": [
        "#Change directory to my folder for analytics labs where I have cloned my gitHub repositories with magic command.\n",
        "\n",
        "%cd drive/My Drive/Data_analytics_lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgrJWLO5kd-A"
      },
      "source": [
        "### Reading JSON file\n",
        "\n",
        "Using the pd.read_json() function the json file is brought into a pandas DataFrame, with the *lines* parameter as *True*- because every new object is separated by a new line. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl5j3OTIG84k"
      },
      "source": [
        "#Read file and view first ten rows\n",
        "mc_df= pd.read_json(\"/content/drive/MyDrive/Data_analytics_lab/Laboration_2/Data/modcloth_final_data.json\", lines=True)\n",
        "\n",
        "mc_df.head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22WfPo3bA5Vs"
      },
      "source": [
        "Time to investigate our dataframe. Answer the following questions:\n",
        "\n",
        "**Q**\n",
        "\n",
        ">\n",
        ">Which datatypes are in our dataframe? What does it tell us about our data in regards to scale (HINT! Measurement scale:Nominal,Ordinal,Inverval,Ratio. Continous/Kategorial data)\n",
        ">\n",
        ">How many rows and columns?\n",
        ">\n",
        ">What does the first column represent?\n",
        "\n",
        "Interpretetion of features: \n",
        "\n",
        "The following features exist in our data, describe shortly how you interpret them and how the data has been collected (to your understanding): \n",
        "\n",
        "- item_id:\n",
        "- waist:\n",
        "- size:\n",
        "- quality:\n",
        "- cup size:\n",
        "- hips:\n",
        "- bra size:\n",
        "- category:\n",
        "- bust:\n",
        "- height:\n",
        "- user_name:\n",
        "- length:\n",
        "- fit:\n",
        "- user_id:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwVFRfKsfHVe"
      },
      "source": [
        "#Which datatypes are in our dataframe?\r\n",
        "print(f'{mc_df.dtypes}\\n')\r\n",
        "# int64, float64 and object with the majority being object. It tells us most of the data is either nominal or interval. \r\n",
        "\r\n",
        "# How many rows and columns?\r\n",
        "# 18 columns and 82790 rows.\r\n",
        "print(f'Column count: \\t {len(mc_df.columns)} \\nRow count: \\t {len(mc_df)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-n7qq3xA5Vs"
      },
      "source": [
        "<a id=\"4\"></a>\n",
        "# EDA - Exploratory Data Analysis\n",
        "\n",
        "We can already make few observations here, by looking at the head of the data:\n",
        "1. There are missing values across the dataframe, which need to be handled.\n",
        "2. Cup-size contains multiple preferences- which will need handling, if we wish to define cup sizes as 'category' datatype.\n",
        "3. Height column needs to be parsed for extracting the height in a numerical quantity, it looks like a string (object) right now.\n",
        "4. Not so important, but some columns could do with some renaming- for removing spaces. One is also using a name `size` that could cause trouble since it is a word used by Pandas, this should be changed.\n",
        "\n",
        "Firstly, we handle the naming of columns for ease-of-access in pandas. It is inconvenient with spaces so remove all of them and replace them with _. Further size is a the keyword in pandas, so we better make sure to change the feature name \"size\" to some user defined name like \"mc_size\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tgDH8i41FpP"
      },
      "source": [
        "#replace white spaces with _ and view dataframe to confirm\n",
        "mc_df.columns =mc_df.columns.str.replace(r'\\s+', '_')\n",
        "\n",
        "\n",
        "mc_df.head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mt-02QhOuOt"
      },
      "source": [
        "#Rename size to mc_size and view dataframe to confirm\n",
        "#Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q3rUtSPaRbF"
      },
      "source": [
        "### Unique number of observations for each feature\n",
        "\n",
        "If the dataset is having less number of observations then we can see the unique values for each feature(There are 82790 observations in the dataset). We will therefore list the number of unique observations for each feature in the dataset. (**HINT!** There is a built in function for this in Pandas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipI-kTFlaVbL"
      },
      "source": [
        "#Investigate the number of unique values for each feature\n",
        "#Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEVK2po_i0eE"
      },
      "source": [
        "* Many of the columns have string values (object as datatype) how should we handle them to make them into usable columns for analysis? \n",
        "\n",
        "* Turn string object that should be numeric data to a correct format (**HINT!** Are they categorial or continous). \n",
        "\n",
        "* Out of the 18 columns, how many columns have complete data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_jDRfC0gAQA"
      },
      "source": [
        "### Identifying outliers\n",
        "\n",
        "* Visualise all the different numerical values in order to identify possible outliers in each of these. Code is provided that define a function for making a boxplot for a feature. \n",
        "\n",
        "  **Q**: \n",
        "  * How does a boxplot help us identify outliers in single features?\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFeASRbuIUo2"
      },
      "source": [
        "The code below define a function which can be used to make boxplot for any numeric feature in the dataset. It will be convenient to use several times, therefore it has been made into a function so you can call it with different features to investigate outliers. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcco6vHYcW6V"
      },
      "source": [
        "def plot_outlier(feature):\n",
        "  plt.figure(figsize=(25, 6))\n",
        "  ax = sns.boxplot(x=feature, linewidth=2.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LjqPysaI10X"
      },
      "source": [
        "* Test the function with a few of the numeric variables in the dataset.\n",
        "\n",
        "* What does the visualizations tell you about potential outliers in your tested features?\n",
        "\n",
        "* Create a new dataframe called `missing_data` which consists of three columns, the feature, total number of missing values and the percantage of missing values for each feature. In the code cell below you have starter code that summarise the missing values and store it in a variable called `missing_data_sum`, you can use it to calculate your columns in `missing_data`.\n",
        "\n",
        "* Investigate the missing data further, why is it missing you think and what type of missing data is it? (HINT! NMAR, MAR, MCAR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc28VmQLA5Vu"
      },
      "source": [
        "#Summarise missing data and find % of missing data\n",
        "missing_data_sum = mc_df.isnull().sum()\n",
        "#Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B09PSRsLnaXV"
      },
      "source": [
        "### Visualize the nonunique observations\n",
        "\n",
        "Some of the observations contain less unique values than others. The below function visualise values. \n",
        "\n",
        "* Create a list that contains  features that you are unsure about whether they are categorial or continous and provide it to the `countplot` function *(max 5 features otherwise it takes to much time)*. \n",
        "\n",
        "* Which of the features would you regard as categorial and which are continous based on the visualizations?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz_d42bUnatZ"
      },
      "source": [
        "def countplot(independent_features):\n",
        "  plt.figure(figsize=(25, 25))\n",
        "  for loc, feature in enumerate(independent_features):\n",
        "    ax = plt.subplot(3, 4, loc+1)\n",
        "    ax.set_xlabel('{}'.format(feature), fontsize=10)\n",
        "    chart = sns.countplot(mc_df[feature])\n",
        "    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFNtOugWNjyO"
      },
      "source": [
        "#List of features and call to function\n",
        "#Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mil-c46_A5Vu"
      },
      "source": [
        "### Statistical description of numerical variables\n",
        "\n",
        "Use the built in functions in Pandas to describe common statistics in regards to the numerical features in the dataset.\n",
        "\n",
        "**Q** \n",
        "\n",
        "* What is the mean cup_size?\n",
        "\n",
        "* What does std stand for?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctqKHOeQA5Vv"
      },
      "source": [
        "#Statistics\n",
        "#Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eBx1abqgiBf"
      },
      "source": [
        "### Further investigation of (some) individual features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTxN2H3uA5Vv"
      },
      "source": [
        "\n",
        "\n",
        "* **shoe_size**: \n",
        "\n",
        "  **Q**:\n",
        "\n",
        "* How does the row(s) containing outlier(s) in the shoe_size feature look like?\n",
        "\n",
        "* What is a suitable way of handling the identified outlier(s) in the shoe_size column? Why? Also, handle the outlier in shoe_size appropriately.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WWiIcHkA5Vw"
      },
      "source": [
        "#View the row that contains the outlier in shoe_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8qFBZQhA5Vx"
      },
      "source": [
        "#Handle the outlier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVjHs1rrA5Vx"
      },
      "source": [
        "## Joint Distribution visualizations\n",
        "Create a visualization that shows the joint distribution of bra_size vs size (bivariate) to get an understanding about the values.\n",
        "\n",
        "**Q:** \n",
        "* What does the visualization tell us?\n",
        "\n",
        "* Can you suggest and implement a visualisation that shows the relationship between the two variables in a clearer way?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klcie-G5A5Vx"
      },
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plt.xlabel(\"bra_size\", fontsize=18)\n",
        "plt.ylabel(\"mc_size\", fontsize=18)\n",
        "plt.suptitle(\"Joint distribution of bra_size vs size\", fontsize= 20)\n",
        "plt.plot(mc_df.bra_size, mc_df['mc_size'], 'bo', alpha=0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBvL0bZ4A5Vy"
      },
      "source": [
        "## Step-by-step features processing:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAe8wPxRWXOk"
      },
      "source": [
        "* **bra_size:**  Looks numerical, but the range is only from 28 to 48, with most of the sizing lying around 34-38. \n",
        "\n",
        "  **Q**: What is a more sensible dtype? Change to this type instead of the present one.\n",
        "\n",
        "  * There are some NA values, this might be due to the store not having this data (yet). Create an 'Unknown' category to replace NA values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqkW7D8gWbpW"
      },
      "source": [
        "#Fix bra_size column\n",
        "mc_df.bra_size = mc_df.bra_size.fillna('Unknown')\n",
        "mc_df.bra_size = mc_df.bra_size.astype('category').cat.as_ordered()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhpoBh9VWkm0"
      },
      "source": [
        "* **bust:** \n",
        "\n",
        "  **Q**: \n",
        "  * What can you infer by looking at the values which are not null? \n",
        "  \n",
        "  * Which dtype is most suitable for bust feature?  Change into this dtype.\n",
        "  \n",
        "  We also need to handle a special case where bust is given as - '37-39'. Replace the entry of '37-39' with the mean. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thi69XwzA5Vy"
      },
      "source": [
        "#Fix bust column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SiOIw0YWvzK"
      },
      "source": [
        "* **category:** none missing; change to dtype category.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Iu2hHrW54k"
      },
      "source": [
        "#Fix category column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIe0snUwXAku"
      },
      "source": [
        "\n",
        "* **cup_size:** Change the dtype to *category* for this column. This column has around 7% missing values. Take a look at the rows where this value is missing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv7c1z00A5Vz",
        "scrolled": true
      },
      "source": [
        "#Fix cup_size column and view a sample of 20 rows where this value is missing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKM-f_OhA5Vz"
      },
      "source": [
        ">We can't see anything glaring from the rows where this data is missing, however, as per the curator of the dataset- \"***Note that these datasets are highly sparse, with most products and customers having only a single transaction.***\" It does point to that maybe these customers have not bought lingerie from modcloth yet and so modcloth does not have that data. So, it makes sense to fill these null values as 'Unknown'. From the prevalence of the values like dd/e, ddd/f, and dddd/g, we can assume these to be legit cup_sizes, also confirmed by [**this**](https://www.herroom.com/full-figure-bra-cup-sizing,905,30.html) article, where some brands change the cup size dd to e, ddd to f etc. We can directly convert this to *category* dtype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaqmuDUmA5Vz"
      },
      "source": [
        "* **fit:** Change the dtype to *category* for this column. \n",
        "\n",
        "  **Q**: \n",
        "\n",
        "  Which feedback has the vast majority of customers given for the fit feature for items on Modcloth?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "737H4HgJXZ8a"
      },
      "source": [
        "#Fix fit column and find the most common value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ePf5oa0A5V0"
      },
      "source": [
        "* **height:** We need to parse the height column as currently it is a string object to a numerical form which is more suitable.  \n",
        "\n",
        "Further:\n",
        "\n",
        "  * Convert height to centimeters instead of inches and feet. This is done in the code below, comment it so it is understandable what it does.\n",
        "\n",
        "  * How many values are missing?\n",
        "\n",
        "  * How many outliers exist? What is suitable to do with the rows containing outliers based on this numer?\n",
        "\n",
        "* Investigate the first 20 rows where the height data is missing. What does it tell us about the customers representing these rows?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh3TXWrBbgg2"
      },
      "source": [
        "#Convert inches and feet to centimeters\n",
        "def height_in_cms(ht):\n",
        "  if ht.lower() != 'nan':\n",
        "    ht = ht.replace('ft','').replace('in', '')\n",
        "    h_ft = int(ht.split()[0])\n",
        "    if len(ht.split()) > 1:\n",
        "      h_inch = int(ht.split()[1])\n",
        "    else:\n",
        "      h_inch = 0\n",
        "    h_inch += h_ft * 12\n",
        "    h_cm = round(h_inch * 2.54, 1)\n",
        "    return h_cm\n",
        "\n",
        "mc_df.height = mc_df.height.astype(str).apply(height_in_cms)\n",
        "mc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5S0kQVuA5V0",
        "scrolled": true
      },
      "source": [
        "mc_df[mc_df.height.isnull()].head(20)\n",
        "# Do look at the output to be able to better understand the inferences!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OqMm1tDA5V0"
      },
      "source": [
        "> This filtering gives us interesting observations here:\n",
        "> 1. Some customers have given bra_size, cup_size data, whereas all other measurements are empty. **Possible first-time purchase at Modcloth for lingerie!**\n",
        "> 2. Some customers have given shoe_size and all other measurements are empty. **Possible first-time purchase at Modcloth for shoes!**\n",
        ">     \n",
        "\n",
        "**It leads us to saying that there are some first-time buyers in the dataset** (let us remeber this for later)\n",
        "\n",
        "  **Q:** \n",
        "\n",
        "  * How can we support this assumption by looking at the data? \n",
        "  \n",
        "  * How many missing values exist in the height feature. \n",
        "  \n",
        "  * What is a suitable course of action for height feature with missing rows?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0dW1g9onpOJ"
      },
      "source": [
        "#Count and handle missing rows \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENLPxBUzA5V1"
      },
      "source": [
        "* **hips:**\n",
        "Hips column has a lot of missing values ~ 32.28%! We know this data would possibly be missing because Modcloth never got this data from the user most probably. We cannot remove such a significant chunk of the data, so we need another way of handling this feature. We will bin the data- on the basis of quartiles. This is done in the code below. \n",
        "\n",
        "* Explain what the code does and what the result is. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OabZVYVehb-F"
      },
      "source": [
        "# Handling hips column\n",
        "mc_df.hips = mc_df.hips.fillna(-1.0)\n",
        "bins = [-5,0,31,37,40,44,75]\n",
        "labels = ['Unknown','XS','S','M', 'L','XL']\n",
        "mc_df.hips = pd.cut(mc_df.hips, bins, labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6bZjo4qhfeA"
      },
      "source": [
        "* **length:** There are only 35 missing rows in length, we'll take a look at these. We saw that most probably the customers did not leave behind the feedback or the data was corrupted in these rows. However, we should be able to impute these values using review related fields (if they are filled!). Or we could also simply choose to remove these rows. For the sake of this analysis, we will remove these rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWm_1L3ehz6J"
      },
      "source": [
        "# Handling length column\n",
        "missing_rows = mc_df[mc_df.length.isnull()].index\n",
        "mc_df.drop(missing_rows, axis = 0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvHZ3nNAhlpC"
      },
      "source": [
        "* **quality:** There are only 68 missing rows in quality, we'll took a look at these. Similarly to length, the customers did not leave behind the feedback or the data was corrupted in these rows. We will remove these rows and convert the dtype to an ordinal variable (ordered categorical)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gD058qzhy7V"
      },
      "source": [
        "# Handling quality\n",
        "missing_rows = mc_df[mc_df.quality.isnull()].index\n",
        "mc_df.drop(missing_rows, axis = 0, inplace=True)\n",
        "mc_df.quality = mc_df.quality.astype('category').cat.as_ordered()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdlHn_vRfhN3"
      },
      "source": [
        "* **review_summary/ review_text**- The NA values are there because these reviews are simply not provided by customers. Let's just fill those as 'Unknown'.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISRXDpz2fuUw"
      },
      "source": [
        "#Handling review_summare/review_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMlQSpTnfkVe"
      },
      "source": [
        "* **shoe_size** -  Roughly 66.3% of the shoe_size data is missing. We will change the shoe_size into *category* dtype and fill the NA values as 'Unknown'.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE3tG2O3fu44"
      },
      "source": [
        "#Handling shoe_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i4yxV9bfmfr"
      },
      "source": [
        "* **shoe_width** - Roughly 77.5% of the shoe_width data is missing, drop this column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGC_VyNMfvh4"
      },
      "source": [
        "#Handling shoe_with"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJnruDkrfo04"
      },
      "source": [
        "* **waist**- Waist column has the highest number of missing values - 96.5%! We will drop this column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcjDWE7nfwK6"
      },
      "source": [
        "#Handling waist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQUH-BfdfqpN"
      },
      "source": [
        "* **bust**- 85.6% missing values and highly correlated to bra_size. Remove.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL1Wjz6afw1G"
      },
      "source": [
        "#Handling bust"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lY-Gjcqfsvu"
      },
      "source": [
        "* **user_name**- user_name itself is not needed with the user_id given. Remove.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJr9y0IYfyKf"
      },
      "source": [
        "#Handling user_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_bZ0Af8Z2MD"
      },
      "source": [
        "Run the function for plotting features again to see how the features look like after our changes, only plot categorial variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqBijCk5aDcL"
      },
      "source": [
        "#Create list and call function to plot features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V51-rlAbHRt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LyqTnB-MgSd"
      },
      "source": [
        "> # Feature Engineering \n",
        "> ## Creating a new feature of first_time_buyer\n",
        "> \n",
        "> Building on our observations above, it makes sense to identify the transactions which belong to first time users. We use the following logic to identify such first time transactions in the dataset:\n",
        "> * If bra_size/cup_size have a value and height, hips, shoe_size, and waist do not we conclude **it is a first time buyer of lingerie**.\n",
        "> * If shoe_size have a value and bra_size, cup_size, height, hips, and waist do not we conclude: **it is a first time buyer of shoes**.\n",
        "> * If hips/waist have a value and bra_size, cup_size, height, shoe_size do not: we conclude: **it is a first time buyer of a dress/tops**.\n",
        "> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YORDKkElA5V1"
      },
      "source": [
        ">Now we add a new column to the original data- *first_time_user*, which is a bool feature which indicates if a user, of a transaction, is a first-time user or not. This is based on the grounds that Modcloth has no previous information about the person, infact it is possible that the new user did multiple transactions in the first time!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VRyZdYbA5V1"
      },
      "source": [
        "lingerie_cond = (((mc_df.bra_size != 'Unknown') | (mc_df.cup_size != 'Unknown')) & (mc_df.height.isnull()) & (mc_df.hips.isnull()) &\n",
        "     (mc_df.shoe_size.isnull()) & (mc_df.shoe_width.isnull()) & (mc_df.waist.isnull()))\n",
        "shoe_cond = ((mc_df.bra_size == 'Unknown') & (mc_df.cup_size == 'Unknown') & (mc_df.height.isnull()) & (mc_df.hips.isnull()) &\n",
        "     ((mc_df.shoe_size.notnull()) | (mc_df.shoe_width.notnull())) & (mc_df.waist.isnull()))\n",
        "dress_cond = ((mc_df.bra_size == 'Unknown') & (mc_df.cup_size == 'Unknown') & (mc_df.height.isnull()) & ((mc_df.hips.notnull()) | (mc_df.waist.notnull())) &\n",
        "     (mc_df.shoe_size.isnull()) & (mc_df.shoe_width.isnull()))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixgcnCoLnUEQ"
      },
      "source": [
        "mc_df['first_time_user'] = (lingerie_cond | shoe_cond | dress_cond)\n",
        "print(\"Column added!\")\n",
        "print(\"Total transactions by first time users who bought bra, shoes, or a dress: \" + str(sum(mc_df.first_time_user)))\n",
        "print(\"Total first time users: \" + str(len(mc_df[(lingerie_cond | shoe_cond | dress_cond)].user_id.unique())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZUEs4yJrHUU"
      },
      "source": [
        "**Q**\n",
        "\n",
        "* How many `first_time_users` did you identify?\n",
        "\n",
        "* How many transactions were made by `first_time_users` who bought bra, shoes, or a dress?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUSGvbKxgdfi"
      },
      "source": [
        "**Q** Are there any missing values left in our dataframe?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juL23IJ8A5V2"
      },
      "source": [
        "\n",
        "## Distribution of different features \n",
        "\n",
        "Now we want to review our remaining features again to see how they look after our cleaning and pre-processing. \n",
        "\n",
        "* Call the plotting function again with a list of all categorial values.\n",
        "\n",
        "* Create a function that plots the continous variables in the dataset and call it with a list of the continous variables. \n",
        "\n",
        "**Q**\n",
        "\n",
        "* What are your observations in regards to the distribution of the data in remaining features? \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRqqhcxph4R7"
      },
      "source": [
        "#Function for plotting continous features\n",
        "def plot_dist(df, independent_features):\n",
        "  plt.figure(figsize=(25, 20))\n",
        "  for loc, feature in enumerate(independent_features):\n",
        "    ax = plt.subplot(3, 3, loc+1)\n",
        "    sns.distplot(df[feature]) # you can try histplot as well\n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zOoT1-iUUb"
      },
      "source": [
        "#Call the function to plot the continous features."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQU5FdS3pwFt"
      },
      "source": [
        "* What do the different visualizations tell us about individual features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERtrQNohA5V2"
      },
      "source": [
        "<a id=\"14\"></a>\n",
        "## Categories vs. Fit, Length and Quality\n",
        "Here, we will visualize how the items of different categories fared in terms of - fit, length, and quality. This will tell Modcloth which categories need more attention! \n",
        "\n",
        "I have plotted 2 distributions in categories here:\n",
        "\n",
        "**1. Unnormalized**- viewing the frequency counts directly- for comparison across categories. We also include the best fit, length, or quality measure in this plot.\n",
        "\n",
        "**2. Normalized** -  viewing the distribution for the category after normalizing the counts, amongst the category itself- it will help us compare what are major reason for return amongst the category itself. We exclude the best sizing & quality measures, so as to focus on the pre-dominant reasons of return per category (if any)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQDlXaZhA5V2"
      },
      "source": [
        "def plot_barh(df,col, cmap = None, stacked=False, norm = None):\n",
        "    df.plot(kind='barh', colormap=cmap, stacked=stacked)\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(24,12)\n",
        "    plt.title(\"Category vs {}-feedback -  Modcloth {}\".format(col, '(Normalized)' if norm else ''), fontsize= 20)\n",
        "    plt.ylabel('Category', fontsize = 18)\n",
        "    plot = plt.xlabel('Frequency', fontsize=18)\n",
        "    \n",
        "def norm_counts(t):\n",
        "    norms = np.linalg.norm(t.fillna(0), axis=1)\n",
        "    t_norm = t[0:0]\n",
        "    for row, euc in zip(t.iterrows(), norms):\n",
        "        t_norm.loc[row[0]] = list(map(lambda x: x/euc, list(row[1])))\n",
        "    return t_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGQzf-uIA5V3"
      },
      "source": [
        "- **Category vs. Fit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgVcCtYvA5V3"
      },
      "source": [
        "g_by_category = mc_df.groupby('category')\n",
        "cat_fit = g_by_category['fit'].value_counts()\n",
        "cat_fit = cat_fit.unstack()\n",
        "cat_fit_norm = norm_counts(cat_fit)\n",
        "cat_fit_norm.drop(['fit'], axis=1, inplace=True)\n",
        "plot_barh(cat_fit, 'fit')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88byI5eoA5V3"
      },
      "source": [
        "\n",
        "* Which categories have the best fit response (`fit`)  \n",
        "* Which categories have the worst fit-feedback?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqTOT1slA5V3"
      },
      "source": [
        "- **Category vs Length**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCyOqa4HA5V4"
      },
      "source": [
        "cat_len = g_by_category['length'].value_counts()\n",
        "cat_len = cat_len.unstack()\n",
        "plot_barh(cat_len, 'length', 'Set3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGJMjfbEA5V4"
      },
      "source": [
        "\n",
        "**Q** Which reason is the most common for returning clothes? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_8j8Sb5A5V5"
      },
      "source": [
        "<a id=\"15\"></a>\n",
        "### Total Number of Users vs Total Number of items bought\n",
        "\n",
        "**Q** What percantage of customers bought only one item at a single transaction? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0H2rnvaA5V5"
      },
      "source": [
        "# Users who bought so many items\n",
        "items_bought = []\n",
        "total_users = []\n",
        "for i in range(min(mc_df.user_id.value_counts()), max(mc_df.user_id.value_counts())+1):\n",
        "    all_users = sum(mc_df.user_id.value_counts() == i)\n",
        "    if all_users != 0:\n",
        "        total_users.append(all_users)\n",
        "        items_bought.append(i)\n",
        "plt.xlabel(\"Number of items bought\", fontsize = 18)\n",
        "plt.ylabel(\"Number of users\", fontsize = 18)\n",
        "plt.title(\"Distribution of items bought by users on Modcloth\")\n",
        "__ = sns.barplot(x=items_bought, y=total_users, color='y')\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(20,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF5Zpx1wA5V5"
      },
      "source": [
        "<a id=\"16\"></a>\n",
        "## Height vs shoe_size -  Modcloth customers\n",
        "It would be interesting to see if there exists a linear relation between the height of a person and their shoe-size, i.e.- it will mean shoe-size increases with increase in height!\n",
        "\n",
        "* Investigate the correlation between shoe_size and height for the customers of Modcloth. \n",
        "\n",
        "* Create a visualisation that show the correlation between the two variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOrNHfwoA5V5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}